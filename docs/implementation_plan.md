# PixelQuery êµ¬í˜„ ê³„íš: ìƒìš©í™” ê´€ì ì˜ ëƒ‰ì •í•œ í‰ê°€ì™€ ì‹¤í–‰ ì „ëµ

## Executive Summary

**ê²°ë¡ **: ì§„í–‰ ê°€ëŠ¥í•˜ë‚˜, **ì¤‘ëŒ€í•œ ìœ„í—˜ ìš”ì†Œ**ë“¤ì„ ì¸ì§€í•˜ê³  ë‹¨ê³„ë³„ ê²€ì¦ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.

**í•µì‹¬ ë°œê²¬**:
- ë””ìì¸ ë¬¸ì„œì˜ ê¸°ë³¸ ê°€ì •("Iceberg for Raster")ì— **ê¸°ìˆ ì  ì˜¤ë¥˜** ì¡´ì¬
- ì‹¤ì œ êµ¬í˜„ ë‚œì´ë„ëŠ” ë¬¸ì„œ ì¶”ì •(8ì£¼)ì˜ **2-2.5ë°°** (14-19ì£¼)
- ì‹œì¥ì€ ì´ë¯¸ COG+STACìœ¼ë¡œ í‘œì¤€í™”ë˜ì–´ ìˆì–´ **ì „í™˜ ë¹„ìš©ì´ ë§¤ìš° ë†’ìŒ**
- í•˜ì§€ë§Œ **ë©€í‹°-ë ˆì¡¸ë£¨ì…˜ í†µí•© ì¿¼ë¦¬**ëŠ” ë…íŠ¹í•œ ê°€ì¹˜ ì œì•ˆ

**ìƒìš©í™” ë¦¬ìŠ¤í¬**: ğŸ”´ HIGH
- ê¸°ìˆ  ë¦¬ìŠ¤í¬: MEDIUM-HIGH (íŠ¸ëœì­ì…˜, ì„±ëŠ¥)
- ì‹œì¥ ë¦¬ìŠ¤í¬: HIGH (ì „í™˜ ë¹„ìš©, ê¸°ì¡´ ì†”ë£¨ì…˜)
- PMF ë¶ˆí™•ì‹¤ì„±: VERY HIGH

**ê¶Œì¥ ì „ëµ**: "Lean Startup" ë°©ì‹
1. **Phase 0-1**: ì¸í„°í˜ì´ìŠ¤ + PoC (4ì£¼) â†’ **ì²« ê²€ì¦ í¬ì¸íŠ¸**
2. **Phase 2**: MVP (6ì£¼) â†’ **ì‹œì¥ ê²€ì¦ (íŒŒì¼ëŸ¿ ê³ ê° í™•ë³´)**
3. **Phase 3-4**: ì „ì²´ êµ¬í˜„ (9ì£¼) â†’ íŒŒì¼ëŸ¿ ì„±ê³µ ì‹œì—ë§Œ ì§„í–‰

---

## 1. ëƒ‰ì •í•œ í‰ê°€: ìƒìš©í™” ê´€ì 

### 1.1 ê¸°ìˆ ì  ê²°í•¨ ë¶„ì„

#### âŒ **Critical Flaw**: "Iceberg for Raster"ëŠ” ê¸°ìˆ ì ìœ¼ë¡œ ë¶€ì •í™•

**ë°œê²¬ëœ ë¬¸ì œ**:
```
ë””ìì¸ ë¬¸ì„œ ì£¼ì¥: "Apache Iceberg for Satellite Imagery"
ì‹¤ì œ:
- IcebergëŠ” ë˜ìŠ¤í„° ë°ì´í„°ë¥¼ ë„¤ì´í‹°ë¸Œë¡œ ì§€ì›í•˜ì§€ ì•ŠìŒ (ë©”íƒ€ë°ì´í„°ë§Œ)
- í”½ì…€ ë°ì´í„°ëŠ” Arrow íŒŒì¼ì— ë³„ë„ ì €ì¥ â†’ Iceberg ACID ë³´ì¥ ë²”ìœ„ ë°–
- ì§„ì§œ ë˜ìŠ¤í„°ìš© IcebergëŠ” "Havasu" (ê²½ìŸì)ê°€ ì´ë¯¸ ì¡´ì¬
```

**ì‹¤ì œ ì•„í‚¤í…ì²˜**:
```
í˜„ì¬ ë””ìì¸:
  Iceberg Table (metadata only, ACID âœ“)
       â†“ references
  Arrow Files (pixel data, ACID âœ—)  â† ì—¬ê¸°ê°€ ë¬¸ì œ!
```

**í”½ì…€ ë°ì´í„°ëŠ” ACID ë³´ì¥ì´ ì•ˆ ë¨** â†’ Two-phase commit ì§ì ‘ êµ¬í˜„ í•„ìš”

#### ğŸŸ¡ **ì„±ëŠ¥ ìš°ë ¤**

**ëª©í‘œ vs í˜„ì‹¤**:
| ëª©í‘œ (ë””ìì¸ ë¬¸ì„œ) | MVP ì˜ˆìƒì¹˜ | í”„ë¡œë•ì…˜ ëª©í‘œ |
|-------------------|-----------|--------------|
| 10 íƒ€ì¼ ì¿¼ë¦¬ < 100ms | 300-500ms | 150ms |
| ì´ë¯¸ì§€ ì¶”ê°€ < 10s | 15-20s | 10s |
| ë¦¬ìƒ˜í”Œë§ ì˜¤ë²„í—¤ë“œ | ë¯¸ì¸¡ì • | ë³‘ëª© ê°€ëŠ¥ |

ì´ˆê¸° ì„±ëŠ¥ì€ ëŠë¦´ ê²ƒ â†’ ìµœì í™” ë°˜ë³µ í•„ìˆ˜

### 1.2 ì‹œì¥ ë¶„ì„: ë ˆë“œì˜¤ì…˜

#### ê²½ìŸ êµ¬ë„

**ì§ì ‘ ê²½ìŸì**:
1. **COG + STAC + DuckDB** (ë¬´ë£Œ, ì˜¤í”ˆì†ŒìŠ¤)
   - í˜„ì¬ ì—…ê³„ í‘œì¤€
   - Planet, NASA, ESA ëª¨ë‘ ì‚¬ìš©
   - "ì¶©ë¶„íˆ ì¢‹ìŒ" (Good Enough)

2. **Havasu** (Iceberg ê¸°ë°˜ ë˜ìŠ¤í„° í¬ë§·)
   - Wherobots ì§€ì›
   - ì´ë¯¸ ë™ì¼ ë¬¸ì œ í•´ê²° ì¤‘
   - ë” ë§ì€ ë¦¬ì†ŒìŠ¤

3. **Google Earth Engine** (ìƒìš©)
   - ì••ë„ì  ì‹œì¥ ì ìœ ìœ¨
   - ì—°êµ¬ìë“¤ ì‚¬ì´ í‘œì¤€

**PixelQuery ì°¨ë³„ì **:
- âœ… **ë©€í‹°-ë ˆì¡¸ë£¨ì…˜ ë„¤ì´í‹°ë¸Œ** (ë…íŠ¹í•¨!)
- âœ… Python-first, ì˜¤í”ˆì†ŒìŠ¤
- âœ… ACID ë©”íƒ€ë°ì´í„° (Iceberg)
- âŒ í”½ì…€ ACIDëŠ” ë³µì¡/ë¶ˆí™•ì‹¤

**ì‹œì¥ í¬ì§€ì…”ë‹**:
```
"Apache Iceberg for Raster" (X)
          â†“
"Multi-Resolution Satellite Data Lake" (O)
```

#### íƒ€ê²Ÿ ê³ ê° í˜„ì‹¤ ì²´í¬

| ê³ ê°êµ° | ê°€ëŠ¥ì„± | ì´ìœ  |
|--------|--------|------|
| **Planet/Airbus** | ğŸ”´ Very Low | ì´ë¯¸ COG+STAC ì¸í”„ë¼ íˆ¬ì, ì „í™˜ ë¹„ìš© ë†’ìŒ |
| **êµ­ë°©/ì •ë³´ê¸°ê´€** | ğŸŸ¡ Low-Medium | Time Travel ë§¤ë ¥ì ì´ë‚˜ ê²€ì¦ëœ ê¸°ìˆ ë§Œ ì‚¬ìš© (1-2ë…„ í›„) |
| **AgriTech ìŠ¤íƒ€íŠ¸ì—…** | ğŸŸ¢ Medium-High | ì‹œê³„ì—´ ì¿¼ë¦¬ í•„ìš”, ì˜ˆì‚° ë¯¼ê°, ìƒˆ ë„êµ¬ ì‹œë„ ì˜í–¥ â­ |
| **ì¬ë‚œ ëª¨ë‹ˆí„°ë§** | ğŸŸ¢ Medium | ë¹ ë¥¸ ë©€í‹°ì†ŒìŠ¤ í†µí•© í•„ìš” |
| **ì—°êµ¬ê¸°ê´€** | ğŸŸ¢ Medium | ì˜¤í”ˆì†ŒìŠ¤ ì„ í˜¸, ìƒˆë¡œìš´ ì ‘ê·¼ë²• ì‹œë„ |

**1ë…„ì°¨ í˜„ì‹¤ì  ëª©í‘œ**:
- íŒŒì¼ëŸ¿ ê³ ê°: 3-5ê°œ (AgriTech, ì—°êµ¬ì†Œ)
- ìœ ë£Œ ì „í™˜: 1-2ê°œ
- ìˆ˜ìµ: $10K-30K (ì—°ê°„)
- **ì°½ì—… ëª©í‘œë¼ë©´ ë§¤ìš° ë¶€ì¡±** â†’ Side Projectë‚˜ ê¸°ìˆ  ê²€ì¦ ë‹¨ê³„ë¡œ ì í•©

### 1.3 ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­

#### íƒ€ì„ë¼ì¸ (1ì¸ ê°œë°œì)

| Phase | ê¸°ê°„ | ëˆ„ì  | ìœ„í—˜ë„ |
|-------|------|------|--------|
| Phase 0: ì¸í„°í˜ì´ìŠ¤ + íŠ¸ëœì­ì…˜ PoC | 2ì£¼ | 2ì£¼ | ğŸ”´ HIGH |
| Phase 1: Foundation | 3ì£¼ | 5ì£¼ | ğŸŸ¡ MEDIUM |
| Phase 2: Storage & Ingestion | 6ì£¼ | 11ì£¼ | ğŸ”´ HIGH |
| Phase 3: Query Engine | 5ì£¼ | 16ì£¼ | ğŸŸ¡ MEDIUM |
| Phase 4: Testing & Optimization | 3ì£¼ | 19ì£¼ | ğŸŸ¢ LOW |

**ì´ 19ì£¼ â‰ˆ 4.5ê°œì›”** (í’€íƒ€ì„ ê¸°ì¤€)

#### í•„ìš” ìŠ¤í‚¬ì…‹ (í˜„ì‹¤ ì²´í¬)

- [ ] Geospatial (CRS, íˆ¬ì˜ë²•, ë¦¬ìƒ˜í”Œë§) - **í•„ìˆ˜**
- [ ] ë¶„ì‚° ì‹œìŠ¤í…œ (ACID, Iceberg, ë™ì‹œì„±) - **í•„ìˆ˜**
- [ ] Python ì„±ëŠ¥ ìµœì í™” (NumPy, Cython) - **ì¤‘ìš”**
- [ ] Data Engineering (Parquet, Arrow) - **í•„ìˆ˜**
- [ ] DevOps (S3, AWS Glue, ë°°í¬) - **ì¤‘ìš”**

**ë¶€ì¡±í•œ ìŠ¤í‚¬ì´ ìˆë‹¤ë©´ í•™ìŠµ ì‹œê°„ +2-4ì£¼**

#### ë¹„ìš© (1ë…„ì°¨)

```
ê°œë°œ ì¸í”„ë¼:
- S3 ë²„í‚· ($50/ì›” Ã— 12) = $600
- AWS Glue í…ŒìŠ¤íŠ¸ ($100/ì›” Ã— 6) = $600
- ìœ„ì„± ë°ì´í„° ë‹¤ìš´ë¡œë“œ = $200-500 (ì¼íšŒì„±)

ìš´ì˜ (íŒŒì¼ëŸ¿ ê³ ê°):
- S3 ìŠ¤í† ë¦¬ì§€ (10TB) = $230/ì›” Ã— 12 = $2,760
- ë°ì´í„° ì „ì†¡ = $500-1,000/ë…„

Total Year 1: $4,650 - $5,500

ìˆ˜ìµ ì˜ˆìƒ: $10K-30K
ì†ìµ: +$5K - $25K (ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤)
```

### 1.4 í‚¬ëŸ¬ ë¦¬ìŠ¤í¬

#### ğŸš¨ í”„ë¡œì íŠ¸ë¥¼ ì£½ì¼ ìˆ˜ ìˆëŠ” ìš”ì¸ë“¤

**1. íŠ¸ëœì­ì…˜ ì›ìì„± ë¬¸ì œ í•´ê²° ì‹¤íŒ¨** (í™•ë¥ : 40%)
- Two-phase commitì´ ë„ˆë¬´ ë³µì¡í•˜ê±°ë‚˜ ëŠë¦¼
- â†’ **ëŒ€ì‘**: Phase 0ì—ì„œ PoC ê²€ì¦, ì‹¤íŒ¨ ì‹œ "ë©”íƒ€ë°ì´í„°ë§Œ ACID" ë¡œ í”¼ë²—

**2. ì„±ëŠ¥ì´ ëª©í‘œì¹˜ì— ëª» ë¯¸ì¹¨** (í™•ë¥ : 60%)
- ë¦¬ìƒ˜í”Œë§ ë³‘ëª©, S3 ë ˆì´í„´ì‹œ
- â†’ **ëŒ€ì‘**: Rust extension, ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬

**3. "Good Enough" ë¬¸ì œ** (í™•ë¥ : 70%)
- COG+STACì´ ëŒ€ë¶€ë¶„ ì‚¬ìš© ì‚¬ë¡€ ì»¤ë²„
- ê³ ê°ì´ ì „í™˜í•  ì´ìœ  ë¶€ì¡±
- â†’ **ëŒ€ì‘**: í‚¬ëŸ¬ ê¸°ëŠ¥ ê°œë°œ (ì‹¤ì‹œê°„ ì‹œê³„ì—´ ë¶„ì„ ëŒ€ì‹œë³´ë“œ?)

**4. Havasuê°€ ëŒ€ì„¸ê°€ ë¨** (í™•ë¥ : 50%)
- Wherobotsì˜ ë¦¬ì†ŒìŠ¤ê°€ ì••ë„
- â†’ **ëŒ€ì‘**: "Python ìƒíƒœê³„ë¥¼ ìœ„í•œ ê²½ëŸ‰ ëŒ€ì•ˆ" í¬ì§€ì…”ë‹

**5. íŒŒì¼ëŸ¿ ê³ ê° í™•ë³´ ì‹¤íŒ¨** (í™•ë¥ : 50%)
- ì‹¤ì œ í˜ì¸í¬ì¸íŠ¸ê°€ ì•„ë‹˜
- â†’ **ëŒ€ì‘**: Phase 2 ì™„ë£Œ í›„ ì¦‰ì‹œ ê³ ê° ì¸í„°ë·°, ì—†ìœ¼ë©´ ì¤‘ë‹¨

---

## 2. ì¸í„°í˜ì´ìŠ¤ ìš°ì„  êµ¬í˜„ ì „ëµ

### 2.1 í•µì‹¬ ì›ì¹™

**"Contract-First Development"**:
1. ëª¨ë“  êµ¬í˜„ ì „ì— ì¸í„°í˜ì´ìŠ¤(Protocol) ì •ì˜
2. ì¸í„°í˜ì´ìŠ¤ë¡œ ë¨¼ì € í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
3. Mock êµ¬í˜„ìœ¼ë¡œ ì‚¬ìš©ì„± ê²€ì¦
4. ì‹¤ì œ êµ¬í˜„ì€ ë§ˆì§€ë§‰

**ì´ì **:
- API ì•ˆì •ì„± í™•ë³´
- ë³‘ë ¬ ê°œë°œ ê°€ëŠ¥ (ì—¬ëŸ¬ íŒ€/ê¸°ì—¬ì)
- ì¡°ê¸° í”¼ë“œë°±
- ë¦¬íŒ©í† ë§ ìš©ì´

### 2.2 Phase 0: ì¸í„°í˜ì´ìŠ¤ ì •ì˜ + ìœ„í—˜ ê²€ì¦ (2ì£¼) ğŸ”´ CRITICAL

#### ëª©í‘œ

1. **ëª¨ë“  í•µì‹¬ ì¸í„°í˜ì´ìŠ¤ ì •ì˜** (Protocol ê¸°ë°˜)
2. **íŠ¸ëœì­ì…˜ PoC** - ACID ê°€ëŠ¥ì„± ê²€ì¦
3. **í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ì¼ˆë ˆí†¤** - Mockìœ¼ë¡œ E2E í”Œë¡œìš°

#### í•µì‹¬ íŒŒì¼

##### 1. `/pixelquery/core/interfaces.py`

ëª¨ë“  ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤ ì •ì˜:

```python
from typing import Protocol, List, Tuple, Optional, Dict
from datetime import datetime
import numpy as np

# === Product ê´€ë ¨ ===

class BandInfo(Protocol):
    """ë°´ë“œ ë©”íƒ€ë°ì´í„°"""
    native_name: str       # "B04"
    standard_name: str     # "red"
    wavelength: float      # 665 (nm)
    resolution: float      # 10.0 (m)

class ProductProfile(Protocol):
    """ìœ„ì„± ì œí’ˆ í”„ë¡œí•„"""
    product_id: str
    provider: str
    sensor: str
    native_resolution: float
    bands: Dict[str, BandInfo]
    scale_factor: float
    nodata: int

# === Tile Grid ===

class TileGrid(Protocol):
    """ì§€ë¦¬ì  íƒ€ì¼ ê·¸ë¦¬ë“œ"""
    def get_tile_id(self, lon: float, lat: float) -> str:
        """ì¢Œí‘œ â†’ tile_id (e.g., 'x0024_y0041')"""
        ...

    def get_tile_bounds(self, tile_id: str) -> Tuple[float, float, float, float]:
        """tile_id â†’ (minx, miny, maxx, maxy)"""
        ...

    def get_pixels_for_resolution(self, resolution_m: float) -> int:
        """í•´ìƒë„ â†’ íƒ€ì¼ë‹¹ í”½ì…€ ìˆ˜"""
        ...

# === Storage ===

class StorageBackend(Protocol):
    """ìŠ¤í† ë¦¬ì§€ ì¶”ìƒí™”"""
    def read_bytes(self, path: str) -> bytes: ...
    def write_bytes(self, path: str, data: bytes) -> None: ...
    def atomic_rename(self, src: str, dest: str) -> None: ...
    def delete(self, path: str) -> None: ...
    def exists(self, path: str) -> bool: ...

# === Transaction ===

class Transaction(Protocol):
    """ACID íŠ¸ëœì­ì…˜"""
    def stage_arrow_chunk(self, tile_id: str, year_month: str, data: dict) -> str:
        """Arrow ì²­í¬ë¥¼ ì„ì‹œ ê²½ë¡œì— ì €ì¥"""
        ...

    def stage_geoparquet_metadata(self, records: List[dict]) -> str:
        """GeoParquet ë©”íƒ€ë°ì´í„°ë¥¼ ì„ì‹œ ê²½ë¡œì— ì €ì¥"""
        ...

    def commit(self) -> dict:
        """Iceberg ì»¤ë°‹ + ì„ì‹œ íŒŒì¼ ìµœì¢…í™” (atomic)
        Returns: {"snapshot_id": int, "files_written": List[str]}
        """
        ...

    def rollback(self) -> None:
        """ì‹¤íŒ¨ ì‹œ ì„ì‹œ íŒŒì¼ ì‚­ì œ"""
        ...

class TransactionManager(Protocol):
    """íŠ¸ëœì­ì…˜ ê´€ë¦¬ì"""
    def begin(self) -> Transaction: ...

# === Query ===

class QueryResult(Protocol):
    """ì¿¼ë¦¬ ê²°ê³¼"""
    tiles: List[dict]  # [{tile_id, date, bands: {red: ndarray, ...}}]

    def to_pandas(self) -> "pd.DataFrame": ...
    def to_xarray(self) -> "xr.Dataset": ...
    def to_numpy(self) -> Dict[str, np.ndarray]: ...

# === Main API ===

class PixelQuery(Protocol):
    """ë©”ì¸ API"""
    def add_image(
        self,
        image_path: str,
        acquisition_date: datetime,
        product_id: str,
        **metadata
    ) -> dict:
        """ì´ë¯¸ì§€ ì¶”ê°€ (ACID)"""
        ...

    def query_by_bounds(
        self,
        bounds: Tuple[float, float, float, float],
        date_range: Tuple[datetime, datetime],
        bands: List[str],
        target_resolution: float = 10.0,
        as_of_snapshot_id: Optional[int] = None
    ) -> QueryResult:
        """ê³µê°„+ì‹œê°„ ì¿¼ë¦¬"""
        ...
```

##### 2. `/pixelquery/transactions/two_phase_commit.py`

**ğŸ”´ MOST CRITICAL - íŠ¸ëœì­ì…˜ PoC**

```python
class TwoPhaseCommitTransaction:
    """
    Two-Phase Commit í”„ë¡œí† íƒ€ì…

    ëª©í‘œ: Arrow + GeoParquet + Icebergë¥¼ ì›ìì ìœ¼ë¡œ ì»¤ë°‹ ê°€ëŠ¥í•œê°€?

    ì „ëµ:
    1. PREPARE: ëª¨ë“  ë°ì´í„°ë¥¼ .tmp íŒŒì¼ë¡œ ì €ì¥
    2. COMMIT: Iceberg ë‚™ê´€ì  ë™ì‹œì„± ì»¤ë°‹ ì‹œë„
    3. FINALIZE: Iceberg ì„±ê³µ ì‹œ .tmp â†’ ìµœì¢… ê²½ë¡œ (atomic rename)
    4. ROLLBACK: ì‹¤íŒ¨ ì‹œ .tmp íŒŒì¼ ì‚­ì œ
    """

    def __init__(self, storage: StorageBackend, iceberg_table):
        self._storage = storage
        self._iceberg_table = iceberg_table
        self._staged_files: List[Tuple[str, str]] = []  # (temp, final)
        self._committed = False

    def stage_arrow_chunk(self, tile_id: str, year_month: str, data: dict) -> str:
        """1ë‹¨ê³„: Arrow â†’ .tmp"""
        temp_path = f"tiles/{tile_id}/{year_month}.arrow.tmp"
        final_path = f"tiles/{tile_id}/{year_month}.arrow"

        # Arrow í…Œì´ë¸” ìƒì„±
        import pyarrow as pa
        table = pa.table(data)

        # ì„ì‹œ íŒŒì¼ì— ì“°ê¸°
        with pa.ipc.new_file(temp_path, table.schema) as writer:
            writer.write_table(table)

        self._staged_files.append((temp_path, final_path))
        return temp_path

    def commit(self) -> dict:
        """2-3ë‹¨ê³„: Iceberg ì»¤ë°‹ + íŒŒì¼ ìµœì¢…í™”"""
        try:
            # 2. Iceberg ë‚™ê´€ì  ë™ì‹œì„± ì»¤ë°‹
            snapshot = self._iceberg_table.append(...)  # GeoParquet ë ˆì½”ë“œ

            # 3. ì„±ê³µ ì‹œ ëª¨ë“  .tmp â†’ ìµœì¢… (atomic!)
            for temp, final in self._staged_files:
                self._storage.atomic_rename(temp, final)

            self._committed = True
            return {"snapshot_id": snapshot.snapshot_id, "files": len(self._staged_files)}

        except Exception as e:
            # 4. ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
            self.rollback()
            raise TransactionError(f"Commit failed: {e}")

    def rollback(self):
        """ì„ì‹œ íŒŒì¼ ì‚­ì œ"""
        for temp, _ in self._staged_files:
            if self._storage.exists(temp):
                self._storage.delete(temp)
```

**âš ï¸ Week 2 ê²€ì¦ í¬ì¸íŠ¸**:
```python
# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
# 1. ì •ìƒ ì»¤ë°‹
# 2. Iceberg ì¶©ëŒ ì‹œ ë¡¤ë°±
# 3. íŒŒì¼ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì‹œ ë¡¤ë°±
# 4. ì„±ëŠ¥ ì¸¡ì • (ì˜¤ë²„í—¤ë“œ < 100ms?)

# ì‹¤íŒ¨ ì‹œ: ACID í¬ê¸°í•˜ê³  "best-effort consistency"ë¡œ í”¼ë²—
```

##### 3. `/pixelquery/core/pixelquery.py`

ë©”ì¸ API ìŠ¤ì¼ˆë ˆí†¤:

```python
class PixelQueryImpl:
    """PixelQuery êµ¬í˜„ (ì´ˆê¸°ì—” Mock)"""

    def __init__(
        self,
        warehouse: str,
        catalog_type: str = "sql",
        storage_backend: Optional[StorageBackend] = None
    ):
        self.warehouse = warehouse
        self._catalog = None  # Lazy init
        self._storage = storage_backend or LocalStorage(warehouse)
        self._tx_manager = None  # Phase 0ì—ì„œ ì´ˆê¸°í™”

    def add_image(
        self,
        image_path: str,
        acquisition_date: datetime,
        product_id: str,
        **metadata
    ) -> dict:
        """Phase 2ì—ì„œ êµ¬í˜„"""
        raise NotImplementedError("Phase 2")

    def query_by_bounds(
        self,
        bounds: Tuple[float, float, float, float],
        date_range: Tuple[datetime, datetime],
        bands: List[str],
        target_resolution: float = 10.0,
        as_of_snapshot_id: Optional[int] = None
    ) -> QueryResult:
        """Phase 3ì—ì„œ êµ¬í˜„"""
        raise NotImplementedError("Phase 3")
```

#### Week 2 ë§ˆì¼ìŠ¤í†¤

```python
# ì´ê²Œ ì‘ë™í•˜ë©´ Phase 0 ì„±ê³µ:

from pixelquery import PixelQuery
from pixelquery.transactions import TwoPhaseCommitTransaction

pq = PixelQuery("./test_warehouse")

# 1. íŠ¸ëœì­ì…˜ PoC í…ŒìŠ¤íŠ¸
tx = pq._tx_manager.begin()
tx.stage_arrow_chunk("x0000_y0000", "2024-01", dummy_data)
result = tx.commit()
print(f"âœ“ Transaction committed: {result}")

# 2. ì¶©ëŒ í…ŒìŠ¤íŠ¸ (ë™ì‹œ ì“°ê¸°)
# ... ë³‘ë ¬ íŠ¸ëœì­ì…˜ ì‹¤í–‰ ...
# í•˜ë‚˜ëŠ” ì„±ê³µ, í•˜ë‚˜ëŠ” ì¬ì‹œë„ í™•ì¸

# 3. ì„±ëŠ¥ ì¸¡ì •
# íŠ¸ëœì­ì…˜ ì˜¤ë²„í—¤ë“œ < 100ms?
```

**GO/NO-GO ê²°ì •**:
- âœ… GO: íŠ¸ëœì­ì…˜ ì‘ë™, ì˜¤ë²„í—¤ë“œ í—ˆìš© ê°€ëŠ¥ â†’ Phase 1 ì§„í–‰
- âŒ PIVOT: íŠ¸ëœì­ì…˜ ë„ˆë¬´ ë³µì¡/ëŠë¦¼ â†’ "ë©”íƒ€ë°ì´í„°ë§Œ ACID" ë¡œ ë³€ê²½

---

### 2.3 Phase 1: Foundation (3ì£¼)

#### ëª©í‘œ

Iceberg + ProductProfile + TileGrid êµ¬í˜„ (í”½ì…€ ë°ì´í„° ì—†ìŒ)

#### êµ¬í˜„ íŒŒì¼

##### 1. `/pixelquery/grid/tile_grid.py`

```python
class TileGridImpl:
    """ì§€ë¦¬ì  íƒ€ì¼ ê·¸ë¦¬ë“œ êµ¬í˜„"""

    def __init__(
        self,
        origin: Tuple[float, float] = (124.0, 33.0),  # í•œêµ­ ê¸°ì¤€
        tile_size_meters: float = 2560.0
    ):
        self.origin = origin
        self.tile_size_meters = tile_size_meters

    def get_tile_id(self, lon: float, lat: float) -> str:
        """WGS84 ì¢Œí‘œ â†’ tile_id"""
        # 1ë„ â‰ˆ 111.32km
        meters_per_degree = 111320.0

        tile_x = int((lon - self.origin[0]) * meters_per_degree / self.tile_size_meters)
        tile_y = int((lat - self.origin[1]) * meters_per_degree / self.tile_size_meters)

        return f"x{tile_x:04d}_y{tile_y:04d}"

    def get_tile_bounds(self, tile_id: str) -> Tuple[float, float, float, float]:
        """tile_id â†’ WGS84 bbox"""
        tile_x, tile_y = self._parse_tile_id(tile_id)

        meters_per_degree = 111320.0
        minx = self.origin[0] + (tile_x * self.tile_size_meters / meters_per_degree)
        miny = self.origin[1] + (tile_y * self.tile_size_meters / meters_per_degree)
        maxx = minx + (self.tile_size_meters / meters_per_degree)
        maxy = miny + (self.tile_size_meters / meters_per_degree)

        return (minx, miny, maxx, maxy)

    def get_pixels_for_resolution(self, resolution_m: float) -> int:
        """í•´ìƒë„ â†’ íƒ€ì¼ë‹¹ í”½ì…€ ìˆ˜

        ì˜ˆ:
        - 10m: 2560m / 10m = 256 í”½ì…€
        - 30m: 2560m / 30m = 85 í”½ì…€
        - 3m: 2560m / 3m = 853 í”½ì…€
        """
        return int(self.tile_size_meters / resolution_m)

    @staticmethod
    def _parse_tile_id(tile_id: str) -> Tuple[int, int]:
        """'x0024_y0041' â†’ (24, 41)"""
        parts = tile_id.split('_')
        tile_x = int(parts[0][1:])
        tile_y = int(parts[1][1:])
        return tile_x, tile_y
```

**í…ŒìŠ¤íŠ¸**:
```python
grid = TileGridImpl()

# ì„œìš¸ (37.5665, 126.9780)
tile_id = grid.get_tile_id(126.9780, 37.5665)
# Expected: x0025_y0041 ì •ë„

bounds = grid.get_tile_bounds(tile_id)
# (126.95xx, 37.54xx, 127.02xx, 37.60xx)

pixels_10m = grid.get_pixels_for_resolution(10.0)  # 256
pixels_30m = grid.get_pixels_for_resolution(30.0)  # 85
```

##### 2. `/pixelquery/products/base.py`

```python
from dataclasses import dataclass
from typing import Dict, Optional

@dataclass
class BandInfo:
    native_name: str       # "B04" (Sentinel-2)
    standard_name: str     # "red"
    wavelength: float      # 665 nm
    resolution: float      # 10.0 m
    bandwidth: Optional[float] = None

@dataclass
class ProductProfile:
    product_id: str            # "sentinel2_l2a"
    provider: str              # "ESA"
    sensor: str                # "MSI"
    product_level: str         # "L2A"
    native_resolution: float   # 10.0

    bands: Dict[str, BandInfo]
    scale_factor: float = 1.0
    offset: float = 0.0
    nodata: int = 0

    cloud_band: Optional[str] = None
    native_crs: str = "EPSG:4326"
```

##### 3. `/pixelquery/products/profiles/sentinel2.py`

```python
from pixelquery.products.base import ProductProfile, BandInfo

SENTINEL2_L2A = ProductProfile(
    product_id="sentinel2_l2a",
    provider="ESA",
    sensor="MSI",
    product_level="L2A",
    native_resolution=10.0,

    bands={
        "blue": BandInfo("B02", "blue", 490, 10, 65),
        "green": BandInfo("B03", "green", 560, 10, 35),
        "red": BandInfo("B04", "red", 665, 10, 30),
        "nir": BandInfo("B08", "nir", 842, 10, 115),
        "swir1": BandInfo("B11", "swir1", 1610, 20, 90),
        "swir2": BandInfo("B12", "swir2", 2190, 20, 180),
    },

    scale_factor=0.0001,
    cloud_band="SCL",
)
```

##### 4. `/pixelquery/iceberg/catalog.py`

```python
from pyiceberg.catalog.sql import SqlCatalog
from pyiceberg.schema import Schema
from pyiceberg.types import *

class PixelQueryCatalog:
    """Iceberg ì¹´íƒˆë¡œê·¸ ë˜í¼"""

    def __init__(self, warehouse: str, catalog_type: str = "sql"):
        if catalog_type == "sql":
            # SQLite (ë¡œì»¬ ê°œë°œìš©ë§Œ!)
            self._catalog = SqlCatalog(
                "pixelquery",
                **{
                    "uri": f"sqlite:///{warehouse}/catalog.db",
                    "warehouse": f"file://{warehouse}"
                }
            )
        else:
            raise NotImplementedError(f"Catalog type {catalog_type} not yet supported")

    def create_tile_catalog_table(self) -> "Table":
        """íƒ€ì¼ ì¹´íƒˆë¡œê·¸ í…Œì´ë¸” ìƒì„±"""
        schema = Schema(
            NestedField(1, "tile_id", StringType(), required=True),
            NestedField(2, "tile_x", IntegerType(), required=True),
            NestedField(3, "tile_y", IntegerType(), required=True),
            NestedField(4, "geometry", BinaryType(), required=True),  # WKB
            NestedField(5, "acquisition_date", TimestampType(), required=True),
            NestedField(6, "year_month", StringType(), required=True),
            NestedField(7, "chunk_file_path", StringType(), required=True),
            NestedField(8, "product_id", StringType()),
            NestedField(9, "native_resolution", FloatType()),
            NestedField(10, "band_red_mean", FloatType()),
            NestedField(11, "band_nir_mean", FloatType()),
            # ... ë‚˜ë¨¸ì§€ í•„ë“œ
        )

        partition_spec = PartitionSpec(
            PartitionField(
                source_id=6,  # year_month
                field_id=1000,
                transform=IdentityTransform(),
                name="month_partition"
            )
        )

        return self._catalog.create_table(
            "default.tile_catalog",
            schema=schema,
            partition_spec=partition_spec
        )

    def get_table(self, name: str = "default.tile_catalog"):
        return self._catalog.load_table(name)
```

#### Week 5 ë§ˆì¼ìŠ¤í†¤

```python
from pixelquery import PixelQuery
from pixelquery.products import SENTINEL2_L2A

pq = PixelQuery("./warehouse")

# 1. ì¹´íƒˆë¡œê·¸ ì´ˆê¸°í™”
pq.init_catalog()
# â†’ warehouse/catalog.db ìƒì„±
# â†’ warehouse/tile_catalog/metadata/ ìƒì„±

# 2. ì œí’ˆ í”„ë¡œí•„ ì‚¬ìš©
profile = SENTINEL2_L2A
print(profile.bands["red"].wavelength)  # 665

# 3. íƒ€ì¼ ê·¸ë¦¬ë“œ
from pixelquery.grid import TileGridImpl
grid = TileGridImpl()
tile_id = grid.get_tile_id(127.0, 37.5)
print(tile_id)  # x0027_y0040
```

---

### 2.4 Phase 2: Storage & Ingestion (6ì£¼) ğŸ”´ COMPLEX

#### ëª©í‘œ

COG â†’ íƒ€ì¼ â†’ Arrow ì²­í¬ â†’ GeoParquet ë©”íƒ€ë°ì´í„° â†’ Iceberg ì»¤ë°‹

#### í•µì‹¬ íŒŒì¼

##### 1. `/pixelquery/io/cog_reader.py`

```python
import rasterio
from rasterio.windows import from_bounds
import numpy as np

class COGReader:
    """Cloud Optimized GeoTIFF ë¦¬ë”"""

    def __init__(self, product_profile: ProductProfile):
        self.profile = product_profile

    def read_tile_window(
        self,
        image_path: str,
        tile_bounds: Tuple[float, float, float, float]
    ) -> dict:
        """
        íƒ€ì¼ ì˜ì—­ì˜ í”½ì…€ ë°ì´í„° ì½ê¸°

        Returns:
            {
                "bands": {"red": ndarray(H, W), "nir": ...},
                "shape": (H, W),
                "resolution": float,
                "transform": Affine,
                "nodata_mask": ndarray(bool)
            }
        """
        with rasterio.open(image_path) as src:
            # CRS ë³€í™˜ (WGS84 â†’ ì´ë¯¸ì§€ CRS)
            minx, miny, maxx, maxy = tile_bounds
            # ... rasterio.warp.transform_bounds ...

            # Window ì½ê¸°
            window = from_bounds(*tile_bounds, src.transform)

            # ë°´ë“œ ì½ê¸°
            bands_data = {}
            for std_name, band_info in self.profile.bands.items():
                # ë„¤ì´í‹°ë¸Œ ë°´ë“œëª… â†’ ì¸ë±ìŠ¤ ë§¤í•‘
                band_idx = self._get_band_index(src, band_info.native_name)

                arr = src.read(band_idx, window=window)

                # Scale + offset ì ìš©
                arr = arr.astype(np.float32)
                arr = arr * self.profile.scale_factor + self.profile.offset

                # NoData ë§ˆìŠ¤í‚¹
                nodata = src.nodata or self.profile.nodata
                arr[arr == nodata] = np.nan

                bands_data[std_name] = arr

            return {
                "bands": bands_data,
                "shape": arr.shape,
                "resolution": self.profile.native_resolution,
                "nodata_mask": np.isnan(arr)
            }
```

##### 2. `/pixelquery/storage/arrow_chunk.py`

**ğŸ”´ MOST COMPLEX - ê°€ë³€ í¬ê¸° ë°°ì—´ ê´€ë¦¬**

```python
import pyarrow as pa
import bisect

class ArrowChunkManager:
    """ì›”ë³„ Arrow ì²­í¬ ê´€ë¦¬ (ë©€í‹°-ë ˆì¡¸ë£¨ì…˜)"""

    def append_observation(
        self,
        tile_id: str,
        year_month: str,
        acquisition_date: datetime,
        product_id: str,
        resolution: float,
        bands_data: Dict[str, np.ndarray],  # {"red": (256,256), "nir": ...}
        storage: StorageBackend
    ) -> str:
        """
        ê´€ì¸¡ ë°ì´í„°ë¥¼ ì›”ë³„ ì²­í¬ì— ì¶”ê°€

        í•µì‹¬ ë¡œì§:
        1. ê¸°ì¡´ ì²­í¬ ì½ê¸° (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
        2. ë‚ ì§œìˆœ ì •ë ¬ëœ ìœ„ì¹˜ ì°¾ê¸° (bisect)
        3. ë©”íƒ€ë°ì´í„° ì‚½ì…
        4. Flat ë°°ì—´ì— í”½ì…€ ë°ì´í„° ì‚½ì… (offset ê³„ì‚°!)
        5. ì›ìì  ì“°ê¸° (.tmp â†’ rename)
        """
        chunk_path = f"tiles/{tile_id}/{year_month}.arrow"

        # 1. ê¸°ì¡´ ì²­í¬ ì½ê¸°
        if storage.exists(chunk_path):
            table = pa.ipc.open_file(chunk_path).read_all()

            dates = table["acquisition_dates"][0].to_pylist()
            product_ids = table["product_ids"][0].to_pylist()
            resolutions = table["resolutions"][0].to_pylist()
            shapes = table["pixel_shapes"][0].to_pylist()

            # ê¸°ì¡´ ë°´ë“œ ë°ì´í„° (flat)
            band_red_flat = table["band_red"][0].to_numpy(zero_copy_only=False)
            band_nir_flat = table["band_nir"][0].to_numpy(zero_copy_only=False)
        else:
            # ìƒˆ ì²­í¬
            dates = []
            product_ids = []
            resolutions = []
            shapes = []
            band_red_flat = np.array([], dtype=np.float32)
            band_nir_flat = np.array([], dtype=np.float32)

        # 2. ì‚½ì… ìœ„ì¹˜ ì°¾ê¸° (ì‹œê°„ìˆœ ì •ë ¬ ìœ ì§€)
        insert_idx = bisect.bisect_left(dates, acquisition_date)

        # 3. ë©”íƒ€ë°ì´í„° ì‚½ì…
        dates.insert(insert_idx, acquisition_date)
        product_ids.insert(insert_idx, product_id)
        resolutions.insert(insert_idx, resolution)

        shape = bands_data["red"].shape
        shapes.insert(insert_idx, list(shape))

        # 4. í”½ì…€ ë°ì´í„° ì‚½ì… (offset ê³„ì‚°!)
        # Offset = ì´ì „ ê´€ì¸¡ë“¤ì˜ ì´ í”½ì…€ ìˆ˜
        offset = sum(s[0] * s[1] for s in shapes[:insert_idx])

        # ìƒˆ ë°ì´í„° flat
        new_red_flat = bands_data["red"].flatten()
        new_nir_flat = bands_data["nir"].flatten()

        # ë°°ì—´ì— ì‚½ì…
        band_red_flat = np.insert(band_red_flat, offset, new_red_flat)
        band_nir_flat = np.insert(band_nir_flat, offset, new_nir_flat)

        # 5. Arrow í…Œì´ë¸” ìƒì„±
        new_table = pa.table({
            "tile_id": [tile_id],
            "year_month": [year_month],
            "acquisition_dates": [dates],
            "product_ids": [product_ids],
            "resolutions": [resolutions],
            "pixel_shapes": [shapes],
            "band_red": [band_red_flat.tolist()],
            "band_nir": [band_nir_flat.tolist()],
            "observation_count": [len(dates)],
        })

        # 6. ì›ìì  ì“°ê¸°
        temp_path = chunk_path + ".tmp"
        with pa.ipc.new_file(temp_path, new_table.schema) as writer:
            writer.write_table(new_table)

        storage.atomic_rename(temp_path, chunk_path)

        return chunk_path

    def extract_observation(
        self,
        chunk_path: str,
        date_idx: int,
        bands: List[str],
        storage: StorageBackend
    ) -> dict:
        """
        íŠ¹ì • ê´€ì¸¡ ì¶”ì¶œ (offset ê³„ì‚°)
        """
        table = pa.ipc.open_file(chunk_path).read_all()

        shapes = table["pixel_shapes"][0].to_pylist()
        resolutions = table["resolutions"][0].to_pylist()
        product_ids = table["product_ids"][0].to_pylist()

        # Offset ê³„ì‚°
        offset = sum(s[0] * s[1] for s in shapes[:date_idx])
        size = shapes[date_idx][0] * shapes[date_idx][1]

        # ë°´ë“œ ì¶”ì¶œ
        result = {"bands": {}}
        for band in bands:
            flat = table[f"band_{band}"][0].to_numpy()
            data_1d = flat[offset:offset+size]
            data_2d = data_1d.reshape(shapes[date_idx])
            result["bands"][band] = data_2d

        result["resolution"] = resolutions[date_idx]
        result["product_id"] = product_ids[date_idx]
        result["shape"] = shapes[date_idx]

        return result
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤** (CRITICAL):
```python
# Test 1: Single observation
chunk_mgr.append_observation(
    tile_id="x0000_y0000",
    year_month="2024-01",
    acquisition_date=datetime(2024, 1, 5),
    product_id="sentinel2_l2a",
    resolution=10.0,
    bands_data={"red": np.random.rand(256, 256), "nir": ...}
)

# Test 2: Mixed resolutions
# Sentinel-2 (10m, 256x256)
chunk_mgr.append_observation(..., resolution=10.0, bands_data={"red": (256,256)})

# Landsat-8 (30m, 85x85)
chunk_mgr.append_observation(..., resolution=30.0, bands_data={"red": (85,85)})

# Planet (3m, 853x853)
chunk_mgr.append_observation(..., resolution=3.0, bands_data={"red": (853,853)})

# Verify: ì´ í”½ì…€ ìˆ˜ = 256Â² + 85Â² + 853Â² = 800,370
```

##### 3. `/pixelquery/storage/geoparquet.py`

```python
import geopandas as gpd
from shapely.geometry import box

class GeoParquetWriter:
    """GeoParquet ë©”íƒ€ë°ì´í„° ì‘ì„±"""

    def write_tile_metadata(
        self,
        tile_records: List[dict],
        partition: str,  # "2024-01"
        storage: StorageBackend
    ) -> str:
        """
        íƒ€ì¼ ë©”íƒ€ë°ì´í„°ë¥¼ GeoParquetë¡œ ì €ì¥

        Records:
        [
            {
                "tile_id": "x0024_y0041",
                "tile_x": 24,
                "tile_y": 41,
                "bounds": (127.0, 37.5, 127.02, 37.54),
                "chunk_file_path": "tiles/x0024_y0041/2024-01.arrow",
                "acquisition_date": datetime(...),
                "product_id": "sentinel2_l2a",
                "resolution": 10.0,
                "band_red_mean": 0.15,
                "band_nir_mean": 0.35,
                ...
            }
        ]
        """
        # Shapely geometries ìƒì„±
        geometries = [box(*rec["bounds"]) for rec in tile_records]

        # GeoDataFrame
        gdf = gpd.GeoDataFrame(tile_records, geometry=geometries, crs="EPSG:4326")

        # Parquet ì €ì¥ (GeoParquet í˜•ì‹)
        output_path = f"warehouse/data/month_partition={partition}/data.parquet"
        gdf.to_parquet(output_path, compression="snappy")

        return output_path
```

##### 4. `/pixelquery/core/pixelquery.py` - add_image êµ¬í˜„

```python
def add_image(
    self,
    image_path: str,
    acquisition_date: datetime,
    product_id: str,
    **metadata
) -> dict:
    """ì´ë¯¸ì§€ ì¶”ê°€ (ì „ì²´ í”Œë¡œìš°)"""

    # 1. ì œí’ˆ í”„ë¡œí•„ ë¡œë“œ
    profile = PRODUCT_REGISTRY[product_id]

    # 2. COG ì½ê¸° + íƒ€ì¼ ë¶„í• 
    cog_reader = COGReader(profile)
    grid = self._grid

    tiles_data = []
    with rasterio.open(image_path) as src:
        # ì´ë¯¸ì§€ê°€ ì»¤ë²„í•˜ëŠ” íƒ€ì¼ ID ì°¾ê¸°
        tile_ids = self._get_intersecting_tiles(src.bounds, grid)

        for tile_id in tile_ids:
            tile_bounds = grid.get_tile_bounds(tile_id)

            # íƒ€ì¼ ì˜ì—­ í”½ì…€ ì½ê¸°
            tile_data = cog_reader.read_tile_window(image_path, tile_bounds)
            tile_data["tile_id"] = tile_id
            tile_data["acquisition_date"] = acquisition_date
            tiles_data.append(tile_data)

    # 3. íŠ¸ëœì­ì…˜ ì‹œì‘
    tx = self._tx_manager.begin()

    try:
        year_month = acquisition_date.strftime("%Y-%m")
        geoparquet_records = []

        for tile_data in tiles_data:
            # Arrow ì²­í¬ì— ì¶”ê°€
            chunk_path = tx.stage_arrow_chunk(
                tile_id=tile_data["tile_id"],
                year_month=year_month,
                data={
                    "acquisition_date": acquisition_date,
                    "product_id": product_id,
                    "resolution": profile.native_resolution,
                    "bands_data": tile_data["bands"]
                }
            )

            # GeoParquet ë ˆì½”ë“œ ì¤€ë¹„
            geoparquet_records.append({
                "tile_id": tile_data["tile_id"],
                "chunk_file_path": chunk_path,
                "acquisition_date": acquisition_date,
                "product_id": product_id,
                "resolution": profile.native_resolution,
                "band_red_mean": np.nanmean(tile_data["bands"]["red"]),
                # ...
            })

        # GeoParquet ìŠ¤í…Œì´ì§•
        tx.stage_geoparquet_metadata(geoparquet_records)

        # 4. ì»¤ë°‹
        result = tx.commit()

        return {
            "snapshot_id": result["snapshot_id"],
            "tiles_written": len(tiles_data),
            "chunk_paths": result["files"]
        }

    except Exception as e:
        tx.rollback()
        raise
```

#### Week 11 ë§ˆì¼ìŠ¤í†¤

```python
pq = PixelQuery("./warehouse")

# 1. Sentinel-2 ì¶”ê°€
result = pq.add_image(
    "sentinel2_20240105_T52SCG.tif",
    acquisition_date=datetime(2024, 1, 5),
    product_id="sentinel2_l2a"
)
print(result)
# {
#   "snapshot_id": 1,
#   "tiles_written": 42,
#   "chunk_paths": ["tiles/x0024_y0041/2024-01.arrow", ...]
# }

# 2. Landsat-8 ì¶”ê°€ (ê°™ì€ ì˜ì—­, ë‹¤ë¥¸ í•´ìƒë„!)
result2 = pq.add_image(
    "landsat8_20240107_LC08_116034.tif",
    acquisition_date=datetime(2024, 1, 7),
    product_id="landsat8_l2"
)

# 3. ê²€ì¦: Arrow ì²­í¬ê°€ ë‘ ê´€ì¸¡ í¬í•¨í•˜ëŠ”ì§€
import pyarrow as pa
chunk = pa.ipc.open_file("warehouse/tiles/x0024_y0041/2024-01.arrow").read_all()
print(chunk["observation_count"][0])  # 2
print(chunk["resolutions"][0])  # [10.0, 30.0]
print(chunk["pixel_shapes"][0])  # [[256, 256], [85, 85]]
```

---

### 2.5 Phase 3: Query Engine (5ì£¼)

#### ëª©í‘œ

ê³µê°„+ì‹œê°„ ì¿¼ë¦¬ + ë¦¬ìƒ˜í”Œë§ + ê²°ê³¼ ë°˜í™˜

#### í•µì‹¬ íŒŒì¼

##### 1. `/pixelquery/query/iceberg_scan.py`

```python
import duckdb

class IcebergScanner:
    """Iceberg ê¸°ë°˜ ê³µê°„/ì‹œê°„ ìŠ¤ìº”"""

    def scan_tiles(
        self,
        iceberg_table,
        bounds: Tuple[float, float, float, float],
        date_range: Tuple[datetime, datetime],
        snapshot_id: Optional[int] = None
    ) -> List[dict]:
        """
        Phase 1: Iceberg íŒŒí‹°ì…˜ í”„ë£¨ë‹
        Phase 2: DuckDB ê³µê°„ í•„í„°

        Returns: [{"chunk_file_path": ..., "tile_id": ..., "date": ..., "resolution": ...}]
        """
        # 1. Snapshot ì„ íƒ
        if snapshot_id:
            scan = iceberg_table.scan(snapshot_id=snapshot_id)
        else:
            scan = iceberg_table.scan()

        # 2. íŒŒí‹°ì…˜ í”„ë£¨ë‹ (month_partition)
        start_ym = date_range[0].strftime("%Y-%m")
        end_ym = date_range[1].strftime("%Y-%m")
        # ... Iceberg partition filter ...

        # 3. GeoParquet íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘
        parquet_files = scan.plan_files()

        # 4. DuckDB spatial ì¿¼ë¦¬
        con = duckdb.connect()
        con.install_extension("spatial")
        con.load_extension("spatial")

        minx, miny, maxx, maxy = bounds
        roi_wkt = f"POLYGON(({minx} {miny}, {maxx} {miny}, {maxx} {maxy}, {minx} {maxy}, {minx} {miny}))"

        query = f"""
            SELECT
                chunk_file_path,
                tile_id,
                acquisition_date,
                product_id,
                native_resolution
            FROM read_parquet([{','.join(f"'{f}'" for f in parquet_files)}])
            WHERE ST_Intersects(
                geometry,
                ST_GeomFromText('{roi_wkt}')
            )
            AND acquisition_date BETWEEN ? AND ?
        """

        result = con.execute(query, [date_range[0], date_range[1]]).fetchall()

        return [
            {
                "chunk_file_path": row[0],
                "tile_id": row[1],
                "acquisition_date": row[2],
                "product_id": row[3],
                "resolution": row[4]
            }
            for row in result
        ]
```

##### 2. `/pixelquery/query/resampling.py`

```python
from scipy.ndimage import zoom

def resample_to_target(
    data: np.ndarray,
    src_resolution: float,
    target_resolution: float,
    method: str = "bilinear"
) -> np.ndarray:
    """
    í•´ìƒë„ ë³€í™˜

    ì˜ˆ:
    - Landsat (30m, 85x85) â†’ 10m (256x256): scale=3.0
    - Planet (3m, 853x853) â†’ 10m (256x256): scale=0.3
    """
    if abs(src_resolution - target_resolution) < 0.01:
        return data  # ì´ë¯¸ ê°™ì€ í•´ìƒë„

    scale_factor = src_resolution / target_resolution

    if method == "bilinear":
        order = 1
    elif method == "nearest":
        order = 0
    else:
        order = 3  # cubic

    resampled = zoom(data, scale_factor, order=order)

    return resampled
```

##### 3. `/pixelquery/query/executor.py`

```python
class QueryExecutor:
    """ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""

    def execute_bounds_query(
        self,
        iceberg_table,
        bounds: Tuple[float, float, float, float],
        date_range: Tuple[datetime, datetime],
        bands: List[str],
        target_resolution: float,
        storage: StorageBackend
    ) -> QueryResult:
        """ì „ì²´ ì¿¼ë¦¬ í”Œë¡œìš°"""

        # 1. Iceberg + DuckDB ìŠ¤ìº”
        scanner = IcebergScanner()
        tile_records = scanner.scan_tiles(iceberg_table, bounds, date_range)

        # 2. Arrow ì²­í¬ ë³‘ë ¬ ì½ê¸°
        chunk_mgr = ArrowChunkManager()

        results = []
        for rec in tile_records:
            # ì²­í¬ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            obs = chunk_mgr.extract_observation(
                chunk_path=rec["chunk_file_path"],
                date_idx=0,  # TODO: ë‚ ì§œë¡œ ì¸ë±ìŠ¤ ì°¾ê¸°
                bands=bands,
                storage=storage
            )

            # 3. ë¦¬ìƒ˜í”Œë§
            resampled_bands = {}
            for band_name, band_data in obs["bands"].items():
                resampled = resample_to_target(
                    band_data,
                    src_resolution=obs["resolution"],
                    target_resolution=target_resolution
                )
                resampled_bands[band_name] = resampled

            results.append({
                "tile_id": rec["tile_id"],
                "acquisition_date": rec["acquisition_date"],
                "product_id": rec["product_id"],
                "bands": resampled_bands,
                "resolution": target_resolution
            })

        return QueryResultImpl(results)
```

##### 4. `/pixelquery/query/result.py`

```python
import pandas as pd
import xarray as xr

class QueryResultImpl:
    """ì¿¼ë¦¬ ê²°ê³¼"""

    def __init__(self, tiles: List[dict]):
        self.tiles = tiles

    def to_pandas(self) -> pd.DataFrame:
        """
        Flatten to DataFrame:
        | tile_id | acquisition_date | product_id | band_red | band_nir |
        """
        rows = []
        for tile in self.tiles:
            row = {
                "tile_id": tile["tile_id"],
                "acquisition_date": tile["acquisition_date"],
                "product_id": tile["product_id"],
            }
            # ë°´ë“œëŠ” í‰ê· ê°’ ë˜ëŠ” ì „ì²´ ë°°ì—´
            for band_name, band_data in tile["bands"].items():
                row[f"band_{band_name}"] = band_data.mean()  # ë˜ëŠ” ì „ì²´ array

            rows.append(row)

        return pd.DataFrame(rows)

    def to_xarray(self) -> xr.Dataset:
        """
        ì‹œê³µê°„ íë¸Œ:
        Dimensions: (time, y, x)
        Variables: red, nir, ...
        """
        # TODO: íƒ€ì¼ë“¤ì„ ê³µê°„ì ìœ¼ë¡œ ëª¨ìì´í¬
        pass

    def to_numpy(self) -> Dict[str, np.ndarray]:
        """Raw NumPy arrays"""
        result = {}
        for band_name in self.tiles[0]["bands"].keys():
            arrays = [t["bands"][band_name] for t in self.tiles]
            result[band_name] = np.stack(arrays)
        return result
```

#### Week 16 ë§ˆì¼ìŠ¤í†¤

```python
pq = PixelQuery("./warehouse")

# ë°ì´í„° ì¶”ê°€ (ì´ë¯¸ Phase 2ì—ì„œ ì™„ë£Œ)
# ...

# ğŸ¯ ì¿¼ë¦¬ ì‹¤í–‰!
result = pq.query_by_bounds(
    bounds=(127.0, 37.5, 127.1, 37.6),
    date_range=(datetime(2024, 1, 1), datetime(2024, 1, 31)),
    bands=["red", "nir"],
    target_resolution=10.0
)

# Pandas ë³€í™˜
df = result.to_pandas()
print(df)
#   tile_id  acquisition_date     product_id  band_red  band_nir
# 0 x0024_y0041  2024-01-05     sentinel2_l2a    0.145     0.352
# 1 x0024_y0041  2024-01-07     landsat8_l2      0.138     0.348  â† ë¦¬ìƒ˜í”Œë§ë¨!

# NDVI ê³„ì‚°
df['ndvi'] = (df['band_nir'] - df['band_red']) / (df['band_nir'] + df['band_red'])
print(df['ndvi'])

# âœ… SUCCESS: End-to-End ì¿¼ë¦¬ ì‘ë™!
```

---

### 2.6 Phase 4: Testing & Optimization (3ì£¼)

#### Week 17: ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸

**ë‹¤ìš´ë¡œë“œ**:
1. Sentinel-2 (Copernicus Open Access Hub)
2. Landsat-8 (USGS Earth Explorer)
3. Planet ìƒ˜í”Œ (ê°€ëŠ¥í•˜ë©´)

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```python
# 1. ë‹¨ì¼ ì œí’ˆ (Sentinel-2ë§Œ)
pq.add_image("s2_seoul_20240105.tif", ...)
result = pq.query_by_bounds(...)
# â†’ ê²€ì¦: í”½ì…€ ê°’ ì •í™•ì„±, í†µê³„

# 2. ë©€í‹° ì œí’ˆ (S2 + L8)
pq.add_image("s2_seoul_20240105.tif", ...)
pq.add_image("l8_seoul_20240107.tif", ...)
result = pq.query_by_bounds(..., target_resolution=10.0)
# â†’ ê²€ì¦: ë¦¬ìƒ˜í”Œë§ ì •í™•ì„± (RMSE ê³„ì‚°)

# 3. ë™ì‹œ ì“°ê¸°
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(3) as executor:
    futures = [
        executor.submit(pq.add_image, "s2_tile1.tif", ...),
        executor.submit(pq.add_image, "s2_tile2.tif", ...),
        executor.submit(pq.add_image, "l8_tile1.tif", ...)
    ]
# â†’ ê²€ì¦: íŠ¸ëœì­ì…˜ ì¶©ëŒ ì²˜ë¦¬, ë°ì´í„° ë¬´ê²°ì„±
```

#### Week 18: ì„±ëŠ¥ ìµœì í™”

**í”„ë¡œíŒŒì¼ë§**:
```bash
python -m cProfile -o profile.stats test_query.py
python -m snakeviz profile.stats
```

**ë³‘ëª© ì˜ˆìƒ & ìµœì í™”**:
1. **DuckDB ìŠ¤ìº”**: Hilbert ì»¤ë¸Œ ì •ë ¬ ì¶”ê°€
2. **Arrow ì½ê¸°**: LRU ìºì‹œ, prefetch
3. **ë¦¬ìƒ˜í”Œë§**: ë²¡í„°í™”, Numba JIT
4. **GeoParquet**: ì»¬ëŸ¼ í”„ë£¨ë‹

**ëª©í‘œ**:
- ì¿¼ë¦¬ ë ˆì´í„´ì‹œ: 300ms â†’ 150ms
- ì¸ì œìŠ¤ì…˜: 15s â†’ 10s

#### Week 19: ë¬¸ì„œí™” & íŒ¨í‚¤ì§•

```
/docs/
â”œâ”€â”€ README.md               # Quick Start
â”œâ”€â”€ ARCHITECTURE.md         # ì•„í‚¤í…ì²˜ ìƒì„¸
â”œâ”€â”€ API.md                  # API ë ˆí¼ëŸ°ìŠ¤
â”œâ”€â”€ PERFORMANCE.md          # ë²¤ì¹˜ë§ˆí¬
â””â”€â”€ COMMERCIALIZATION.md    # ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸

/examples/
â”œâ”€â”€ 01_basic_ingestion.py
â”œâ”€â”€ 02_multi_resolution_query.py
â”œâ”€â”€ 03_time_series_analysis.ipynb
â””â”€â”€ 04_ndvi_calculation.ipynb

pyproject.toml              # ì˜ì¡´ì„± ì •ë¦¬
Dockerfile                  # ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€
```

---

## 3. ìƒìš©í™” ì „ëµ & Go/No-Go ê²°ì • í¬ì¸íŠ¸

### 3.1 ë‹¨ê³„ë³„ ê²€ì¦ í¬ì¸íŠ¸

#### ğŸš¦ Checkpoint 1: Week 2 (Phase 0 ì™„ë£Œ)

**ì§ˆë¬¸**: íŠ¸ëœì­ì…˜ PoCê°€ ì‘ë™í•˜ëŠ”ê°€?

âœ… **GO**:
- Two-phase commit ì‘ë™
- ì˜¤ë²„í—¤ë“œ < 100ms
- ì¶©ëŒ ì²˜ë¦¬ ê°€ëŠ¥

âŒ **PIVOT**:
- íŠ¸ëœì­ì…˜ ë„ˆë¬´ ë³µì¡/ëŠë¦¼
- â†’ "ë©”íƒ€ë°ì´í„°ë§Œ ACID" ë¡œ ë³€ê²½
- â†’ í”½ì…€ ë°ì´í„°ëŠ” append-only, best-effort

#### ğŸš¦ Checkpoint 2: Week 11 (Phase 2 ì™„ë£Œ)

**ì§ˆë¬¸**: ì‹¤ì œ ìœ„ì„± ë°ì´í„° ì¸ì œìŠ¤ì…˜ì´ ì‘ë™í•˜ëŠ”ê°€?

âœ… **GO**:
- Sentinel-2 + Landsat-8 ì¸ì œìŠ¤ì…˜ ì„±ê³µ
- Arrow ì²­í¬ ì •í™•ì„± ê²€ì¦ë¨
- ë©€í‹°-ë ˆì¡¸ë£¨ì…˜ ì €ì¥ í™•ì¸

âŒ **STOP**:
- ë°ì´í„° ì†ìƒ, offset ê³„ì‚° ë²„ê·¸
- â†’ ì•„í‚¤í…ì²˜ ì¬ì„¤ê³„ í•„ìš”

#### ğŸš¦ Checkpoint 3: Week 16 (Phase 3 ì™„ë£Œ)

**ì§ˆë¬¸**: ì¿¼ë¦¬ê°€ ì‘ë™í•˜ê³  ì„±ëŠ¥ì´ í—ˆìš© ê°€ëŠ¥í•œê°€?

âœ… **GO**:
- E2E ì¿¼ë¦¬ ì‘ë™
- ë ˆì´í„´ì‹œ < 500ms (ìµœì í™” ì „)
- ë¦¬ìƒ˜í”Œë§ ì •í™•ì„± ê²€ì¦

âŒ **PIVOT**:
- ì„±ëŠ¥ > 2ì´ˆ â†’ Rust extension ê³ ë ¤
- ë˜ëŠ” ì•„í‚¤í…ì²˜ ë³€ê²½ (ì‚¬ì „ ë¦¬ìƒ˜í”Œë§?)

#### ğŸš¦ Checkpoint 4: Week 19 (Phase 4 ì™„ë£Œ)

**ì§ˆë¬¸**: íŒŒì¼ëŸ¿ ê³ ê°ì„ í™•ë³´í•  ìˆ˜ ìˆëŠ”ê°€?

âœ… **GO (ìƒìš©í™”)**:
- 3-5ê°œ íŒŒì¼ëŸ¿ ê³ ê° í™•ë³´
- ê¸ì •ì  í”¼ë“œë°±
- â†’ Phase 5: í”„ë¡œë•ì…˜í™” (ë¶„ì‚° ì²˜ë¦¬, Glue ì¹´íƒˆë¡œê·¸)

âŒ **PIVOT (ì˜¤í”ˆì†ŒìŠ¤)**:
- ê³ ê° í™•ë³´ ì‹¤íŒ¨
- â†’ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì „í™˜, ì»¤ë®¤ë‹ˆí‹° êµ¬ì¶•
- â†’ ì¥ê¸°ì  ìƒìš©í™” ì¬ì‹œë„

### 3.2 ìƒìš©í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

**ê¸°ìˆ ì  ì¤€ë¹„**:
- [ ] í”„ë¡œë•ì…˜ ì¹´íƒˆë¡œê·¸ (AWS Glue)
- [ ] S3 ìŠ¤í† ë¦¬ì§€ ì§€ì›
- [ ] ì—ëŸ¬ ì²˜ë¦¬ & ë¡œê¹…
- [ ] ëª¨ë‹ˆí„°ë§ (Prometheus?)
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

**ë¹„ì¦ˆë‹ˆìŠ¤ ì¤€ë¹„**:
- [ ] íŒŒì¼ëŸ¿ ê³ ê° 3-5ê°œ í™•ë³´
- [ ] ê°€ê²© ëª¨ë¸ ìˆ˜ë¦½ ($99-999/ì›”?)
- [ ] ë²•ì¸ ì„¤ë¦½ (í•„ìš” ì‹œ)
- [ ] ì§€ì ì¬ì‚°ê¶Œ (Apache 2.0 ë¼ì´ì„ ìŠ¤)

**ë§ˆì¼€íŒ…**:
- [ ] GitHub ì˜¤í”ˆì†ŒìŠ¤ ë¦´ë¦¬ì¦ˆ
- [ ] Hacker News, Reddit ê²Œì‹œ
- [ ] ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ (Medium, Dev.to)
- [ ] ì»¨í¼ëŸ°ìŠ¤ ë°œí‘œ (FOSS4G, PyCon)

### 3.3 ìˆ˜ìµ ëª¨ë¸

**Open Core**:
```
ë¬´ë£Œ (Apache 2.0):
- ë¡œì»¬ SQLite ì¹´íƒˆë¡œê·¸
- ë‹¨ì¼ ë…¸ë“œ
- ì»¤ë®¤ë‹ˆí‹° ì§€ì›

Pro ($99-299/ì›”):
- AWS Glue ì¹´íƒˆë¡œê·¸
- S3 ìŠ¤í† ë¦¬ì§€
- ì´ë©”ì¼ ì§€ì›
- ì›” 1TB ë°ì´í„°

Enterprise ($999-2,999/ì›”):
- ë¶„ì‚° ì²˜ë¦¬ (Spark í†µí•©)
- RBAC & ê°ì‚¬ ë¡œê·¸
- SLA ë³´ì¥
- ì „ìš© ì§€ì›
```

**Year 1 ëª©í‘œ**:
- ì˜¤í”ˆì†ŒìŠ¤ ì‚¬ìš©ì: 100-500
- Pro ê³ ê°: 5-10
- Enterprise ê³ ê°: 1-2
- ìˆ˜ìµ: $10K-30K

**Year 2 ëª©í‘œ**:
- ì˜¤í”ˆì†ŒìŠ¤ ì‚¬ìš©ì: 1,000+
- Pro ê³ ê°: 30-50
- Enterprise ê³ ê°: 5-10
- ìˆ˜ìµ: $100K-300K

---

## 4. ìµœì¢… ê¶Œê³ ì‚¬í•­

### 4.1 ëƒ‰ì •í•œ í‰ê°€

**ê¸°ìˆ ì ìœ¼ë¡œ**: âœ… **ê°€ëŠ¥**
- ë³µì¡í•˜ì§€ë§Œ êµ¬í˜„ ê°€ëŠ¥
- PyIceberg/Arrow/DuckDB ì„±ìˆ™ë„ ì¶©ë¶„
- ë©€í‹°-ë ˆì¡¸ë£¨ì…˜ì€ ë…íŠ¹í•œ ê°€ì¹˜

**ì‹œì¥ì ìœ¼ë¡œ**: ğŸŸ¡ **ë¶ˆí™•ì‹¤**
- COG+STACì´ í‘œì¤€, ì „í™˜ ë¹„ìš© ë†’ìŒ
- Havasuì™€ ê²½ìŸ
- í•˜ì§€ë§Œ AgriTech ë“± ë‹ˆì¹˜ ì‹œì¥ ì¡´ì¬

**ìƒìš©í™”ë¡œ**: ğŸ”´ **ê³ ìœ„í—˜**
- Year 1 ìˆ˜ìµ $10K-30K (ë¶€ì¡±)
- íŒŒì¼ëŸ¿ ê³ ê° í™•ë³´ ë¶ˆí™•ì‹¤
- í’€íƒ€ì„ ì°½ì—…ìœ¼ë¡œëŠ” ìœ„í—˜, Side Projectë¡œ ì í•©

### 4.2 ì¶”ì²œ ì „ëµ

**Option A: Lean Startup (ì¶”ì²œ!)**
1. **4ì£¼**: Phase 0-1 ì™„ë£Œ â†’ PoC ë°ëª¨
2. **ê³ ê° ì¸í„°ë·°**: 10-20ê°œ AgriTech/ì—°êµ¬ì†Œ
3. **ê²€ì¦**: 3ê°œ ì´ìƒì´ "ì´ê±° í•„ìš”í•¨"ì´ë¼ë©´ â†’ Phase 2-3
4. **6ì£¼**: MVP ì™„ì„± â†’ íŒŒì¼ëŸ¿ ê³ ê°
5. **ì„±ê³µ ì‹œ**: ì „ì²´ êµ¬í˜„ + ì°½ì—…
6. **ì‹¤íŒ¨ ì‹œ**: ì˜¤í”ˆì†ŒìŠ¤ ì „í™˜

**Option B: ì˜¤í”ˆì†ŒìŠ¤ First**
1. **ì „ì²´ êµ¬í˜„** (19ì£¼)
2. **ì˜¤í”ˆì†ŒìŠ¤ ë¦´ë¦¬ì¦ˆ** (Apache 2.0)
3. **ì»¤ë®¤ë‹ˆí‹° êµ¬ì¶•** (6-12ê°œì›”)
4. **ì‚¬ìš©ì í™•ë³´ í›„** ìƒìš© ì„œë¹„ìŠ¤ ë¡ ì¹­
5. ì¥ê¸° í”Œë ˆì´ (Icebergë„ 3ë…„ ê±¸ë¦¼)

### 4.3 ì–´ëŠ ìª½ì„ ì„ íƒí•  ê²ƒì¸ê°€?

**ìƒìš©í™”ê°€ ëª©í‘œë¼ë©´**:
â†’ **Option A (Lean Startup)** ê°•ë ¥ ì¶”ì²œ
- ë¹ ë¥¸ ì‹œì¥ ê²€ì¦
- ìì› ë‚­ë¹„ ìµœì†Œí™”
- í”¼ë²— ì˜µì…˜ ìœ ì§€

**í•™ìŠµ/í¬íŠ¸í´ë¦¬ì˜¤ ëª©í‘œì˜€ë‹¤ë©´**:
â†’ **Option B (ì˜¤í”ˆì†ŒìŠ¤)** ì¶”ì²œ
- ì™„ì „í•œ êµ¬í˜„ ê²½í—˜
- ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬
- ì¥ê¸°ì  ê°€ì¹˜

---

## 5. êµ¬í˜„ ìš°ì„ ìˆœìœ„ (ì¸í„°í˜ì´ìŠ¤ First)

### Week 1-2: ì¸í„°í˜ì´ìŠ¤ ì •ì˜ + PoC

**íŒŒì¼ ìƒì„± ìˆœì„œ**:
1. `pixelquery/core/interfaces.py` (ëª¨ë“  Protocol)
2. `pixelquery/transactions/two_phase_commit.py` (PoC)
3. `pixelquery/storage/backends.py` (StorageBackend êµ¬í˜„)
4. `tests/test_transactions.py` (íŠ¸ëœì­ì…˜ í…ŒìŠ¤íŠ¸)

**ëª©í‘œ**: ì¸í„°í˜ì´ìŠ¤ë¡œ Mock í…ŒìŠ¤íŠ¸ ì‘ì„±, íŠ¸ëœì­ì…˜ ê²€ì¦

### Week 3-5: Foundation

5. `pixelquery/grid/tile_grid.py`
6. `pixelquery/products/base.py`
7. `pixelquery/products/profiles/sentinel2.py`
8. `pixelquery/products/profiles/landsat8.py`
9. `pixelquery/iceberg/catalog.py`
10. `tests/test_grid.py`, `tests/test_products.py`

### Week 6-11: Storage

11. `pixelquery/io/cog_reader.py`
12. `pixelquery/storage/arrow_chunk.py` (CRITICAL!)
13. `pixelquery/storage/geoparquet.py`
14. `pixelquery/core/pixelquery.py` (add_image)
15. `tests/test_ingestion.py` (ì‹¤ì œ COG ë°ì´í„°)

### Week 12-16: Query

16. `pixelquery/query/iceberg_scan.py`
17. `pixelquery/query/resampling.py`
18. `pixelquery/query/executor.py`
19. `pixelquery/query/result.py`
20. `pixelquery/core/pixelquery.py` (query_by_bounds)
21. `tests/test_query.py` (E2E)

### Week 17-19: Production Ready

22. ë¬¸ì„œí™” (README, API docs)
23. ì˜ˆì œ (Jupyter notebooks)
24. ì„±ëŠ¥ ìµœì í™”
25. íŒ¨í‚¤ì§• (PyPI)
26. Docker ì´ë¯¸ì§€

---

## 6. í•µì‹¬ ë¦¬ìŠ¤í¬ ì™„í™” ì „ëµ

| ë¦¬ìŠ¤í¬ | í™•ë¥  | ì™„í™” ì „ëµ |
|--------|------|----------|
| íŠ¸ëœì­ì…˜ ì‹¤íŒ¨ | 40% | Week 2 PoC, ì‹¤íŒ¨ ì‹œ "ë©”íƒ€ë°ì´í„°ë§Œ ACID" í”¼ë²— |
| ì„±ëŠ¥ ë¶€ì¡± | 60% | Week 18 í”„ë¡œíŒŒì¼ë§, Rust extension ì¤€ë¹„ |
| ê³ ê° í™•ë³´ ì‹¤íŒ¨ | 50% | Week 4 ê³ ê° ì¸í„°ë·°, Week 11 íŒŒì¼ëŸ¿ ëª¨ì§‘ |
| Havasu ê²½ìŸ | 50% | "Python ìƒíƒœê³„" ì°¨ë³„í™”, ë¹ ë¥¸ ë¦´ë¦¬ì¦ˆ |
| ê°œë°œ ì§€ì—° | 70% | ë‹¨ê³„ë³„ ê²€ì¦, ë¶ˆí•„ìš” ê¸°ëŠ¥ ê³¼ê°íˆ ì œê±° |

---

## 7. ê²°ë¡ : ì§„í–‰ ì—¬ë¶€

### âœ… ì§„í–‰ (ì¡°ê±´ë¶€)

**ì¡°ê±´**:
1. **Lean Startup ë°©ì‹** ì±„íƒ (4ì£¼ PoC â†’ ì‹œì¥ ê²€ì¦)
2. **ì¸í„°í˜ì´ìŠ¤ ìš°ì„ ** ê°œë°œ
3. **ë‹¨ê³„ë³„ Go/No-Go** ê²°ì • í¬ì¸íŠ¸ ì¤€ìˆ˜
4. **íŒŒì¼ëŸ¿ ê³ ê° í™•ë³´** ì‹¤íŒ¨ ì‹œ ì˜¤í”ˆì†ŒìŠ¤ ì „í™˜ ê°ì˜¤

**ê¸°ëŒ€ ì„±ê³¼**:
- **ê¸°ìˆ ì **: ë³µì¡í•œ ì‹œìŠ¤í…œ ì„¤ê³„/êµ¬í˜„ ê²½í—˜
- **ì‹œì¥ì **: ì§€ë¦¬ê³µê°„ ë°ì´í„° ì‹œì¥ ì´í•´
- **ë¹„ì¦ˆë‹ˆìŠ¤ì **: ì œí’ˆ ê°œë°œ â†’ ê³ ê° í™•ë³´ ê²½í—˜
- **ê¸ˆì „ì **: Year 1 $10K-30K (ë‚™ê´€ì ), $0 (í˜„ì‹¤ì )

**í˜„ì‹¤ì  íƒ€ì„ë¼ì¸**:
- **PoC**: 4ì£¼
- **ì‹œì¥ ê²€ì¦**: 2-4ì£¼
- **MVP**: 10ì£¼ (ì„±ê³µ ì‹œ)
- **íŒŒì¼ëŸ¿**: 4-8ì£¼
- **ì „ì²´**: ~6ê°œì›” (í’€íƒ€ì„)

### âš ï¸ ì£¼ì˜ì‚¬í•­

ì´ê²ƒì€ **ê³ ìœ„í—˜ í”„ë¡œì íŠ¸**ì…ë‹ˆë‹¤:
- ê¸°ìˆ ì  ë³µì¡ë„ ë†’ìŒ
- ì‹œì¥ ì „í™˜ ë¹„ìš© ë†’ìŒ
- ê²½ìŸì ì¡´ì¬ (Havasu)
- ìˆ˜ìµ ë¶ˆí™•ì‹¤

**ì°½ì—… ëª©ì ì´ë¼ë©´**: Side Projectë¡œ ì‹œì‘ ê¶Œì¥
**í•™ìŠµ ëª©ì ì´ë¼ë©´**: í›Œë¥­í•œ ì„ íƒ

---

## ë‹¤ìŒ ë‹¨ê³„

1. **ì§€ê¸ˆ ë°”ë¡œ**: Phase 0 ì‹œì‘ (ì¸í„°í˜ì´ìŠ¤ ì •ì˜)
2. **Week 2**: íŠ¸ëœì­ì…˜ PoC ê²€ì¦
3. **Week 4**: ê³ ê° ì¸í„°ë·° (10-20ê°œ)
4. **Week 5**: GO/NO-GO ê²°ì •

**ì²« íŒŒì¼ë¶€í„° ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?**
